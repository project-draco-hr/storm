{
  Map<String,RAS_Node> nodeIdToNode=new HashMap<String,RAS_Node>();
  for (  SupervisorDetails sup : cluster.getSupervisors().values()) {
    String id=sup.getId();
    boolean isAlive=!cluster.isBlackListed(id);
    LOG.debug("Found a {} Node {} {}",isAlive ? "living" : "dead",id,sup.getAllPorts());
    LOG.debug("resources_mem: {}, resources_CPU: {}",sup.getTotalMemory(),sup.getTotalCPU());
    nodeIdToNode.put(sup.getId(),new RAS_Node(id,sup.getAllPorts(),isAlive,sup,cluster));
  }
  for (  Map.Entry<String,SchedulerAssignment> entry : cluster.getAssignments().entrySet()) {
    String topId=entry.getValue().getTopologyId();
    for (    WorkerSlot workerSlot : entry.getValue().getSlots()) {
      String id=workerSlot.getNodeId();
      RAS_Node node=nodeIdToNode.get(id);
      if (node == null) {
        LOG.info("Found an assigned slot on a dead supervisor {} with executors {}",workerSlot,RAS_Node.getExecutors(workerSlot,cluster));
        node=new RAS_Node(id,null,false,null,cluster);
        nodeIdToNode.put(id,node);
      }
      if (!node.isAlive()) {
        node.addOrphanedSlot(workerSlot);
      }
      if (node.assignInternal(workerSlot,topId,true)) {
        LOG.warn("Bad scheduling state, " + workerSlot + " assigned multiple workers, unassigning everything...");
        node.free(workerSlot);
      }
    }
  }
  updateAvailableResources(cluster,topologies,nodeIdToNode);
  return nodeIdToNode;
}
