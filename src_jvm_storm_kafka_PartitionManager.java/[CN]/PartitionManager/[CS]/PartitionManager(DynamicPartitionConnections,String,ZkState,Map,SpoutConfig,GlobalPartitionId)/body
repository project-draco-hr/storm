{
  _partition=id;
  _connections=connections;
  _spoutConfig=spoutConfig;
  _topologyInstanceId=topologyInstanceId;
  _consumer=connections.register(id.host,id.partition);
  _state=state;
  _stormConf=stormConf;
  String jsonTopologyId=null;
  Long jsonOffset=null;
  try {
    Map<Object,Object> json=_state.readJSON(committedPath());
    if (json != null) {
      jsonTopologyId=(String)((Map<Object,Object>)json.get("topology")).get("id");
      jsonOffset=(Long)json.get("offset");
    }
  }
 catch (  Throwable e) {
    LOG.warn("Error reading and/or parsing at ZkNode: " + committedPath(),e);
  }
  if (!topologyInstanceId.equals(jsonTopologyId) && spoutConfig.forceFromStart) {
    _committedTo=KafkaUtils.getOffset(_consumer,spoutConfig.topic,id.partition,spoutConfig.startOffsetTime);
    LOG.info("Using startOffsetTime to choose last commit offset.");
  }
 else   if (jsonTopologyId == null || jsonOffset == null) {
    _committedTo=KafkaUtils.getOffset(_consumer,spoutConfig.topic,id.partition,-1);
    LOG.info("Setting last commit offset to HEAD.");
  }
 else {
    _committedTo=jsonOffset;
    LOG.info("Read last commit offset from zookeeper: " + _committedTo);
  }
  LOG.info("Starting Kafka " + _consumer.host() + ":"+ id.partition+ " from offset "+ _committedTo);
  _emittedToOffset=_committedTo;
  _fetchAPILatencyMax=new CombinedMetric(new MaxMetric());
  _fetchAPILatencyMean=new ReducedMetric(new MeanReducer());
  _fetchAPICallCount=new CountMetric();
  _fetchAPIMessageCount=new CountMetric();
}
