{
  try {
    HashMap ret=new HashMap();
    if (_partitions != null && _partitions.size() == _partitionToOffset.size()) {
      Map<String,TopicMetrics> topicMetricsMap=new TreeMap<String,TopicMetrics>();
      for (      Map.Entry<Partition,PartitionManager.OffsetData> e : _partitionToOffset.entrySet()) {
        Partition partition=e.getKey();
        SimpleConsumer consumer=_connections.getConnection(partition);
        if (consumer == null) {
          LOG.warn("partitionToOffset contains partition not found in _connections. Stale partition data?");
          return null;
        }
        long latestTimeOffset=getOffset(consumer,partition.topic,partition.partition,kafka.api.OffsetRequest.LatestTime());
        long earliestTimeOffset=getOffset(consumer,partition.topic,partition.partition,kafka.api.OffsetRequest.EarliestTime());
        if (latestTimeOffset == KafkaUtils.NO_OFFSET) {
          LOG.warn("No data found in Kafka Partition " + partition.getId());
          return null;
        }
        long latestEmittedOffset=e.getValue().latestEmittedOffset;
        long latestCompletedOffset=e.getValue().latestCompletedOffset;
        long spoutLag=latestTimeOffset - latestCompletedOffset;
        String topic=partition.topic;
        String metricPath=partition.getId();
        if (!metricPath.startsWith(topic + "/")) {
          metricPath=topic + "/" + metricPath;
        }
        ret.put(metricPath + "/" + "spoutLag",spoutLag);
        ret.put(metricPath + "/" + "earliestTimeOffset",earliestTimeOffset);
        ret.put(metricPath + "/" + "latestTimeOffset",latestTimeOffset);
        ret.put(metricPath + "/" + "latestEmittedOffset",latestEmittedOffset);
        ret.put(metricPath + "/" + "latestCompletedOffset",latestCompletedOffset);
        if (!topicMetricsMap.containsKey(partition.topic)) {
          topicMetricsMap.put(partition.topic,new TopicMetrics());
        }
        TopicMetrics topicMetrics=topicMetricsMap.get(partition.topic);
        topicMetrics.totalSpoutLag+=spoutLag;
        topicMetrics.totalEarliestTimeOffset+=earliestTimeOffset;
        topicMetrics.totalLatestTimeOffset+=latestTimeOffset;
        topicMetrics.totalLatestEmittedOffset+=latestEmittedOffset;
        topicMetrics.totalLatestCompletedOffset+=latestCompletedOffset;
      }
      for (      Map.Entry<String,TopicMetrics> e : topicMetricsMap.entrySet()) {
        String topic=e.getKey();
        TopicMetrics topicMetrics=e.getValue();
        ret.put(topic + "/" + "totalSpoutLag",topicMetrics.totalSpoutLag);
        ret.put(topic + "/" + "totalEarliestTimeOffset",topicMetrics.totalEarliestTimeOffset);
        ret.put(topic + "/" + "totalLatestTimeOffset",topicMetrics.totalLatestTimeOffset);
        ret.put(topic + "/" + "totalLatestEmittedOffset",topicMetrics.totalLatestEmittedOffset);
        ret.put(topic + "/" + "totalLatestCompletedOffset",topicMetrics.totalLatestCompletedOffset);
      }
      return ret;
    }
 else {
      LOG.info("Metrics Tick: Not enough data to calculate spout lag.");
    }
  }
 catch (  Throwable t) {
    LOG.warn("Metrics Tick: Exception when computing kafkaOffset metric.",t);
  }
  return null;
}
